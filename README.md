# Predicci√≥n de D√≠gitos
Esta aplicaci√≥n implementa un modelo de inteligencia artificial dise√±ado para reconocer e identificar d√≠gitos a partir de im√°genes. Utiliza t√©cnicas avanzadas de procesamiento de im√°genes y aprendizaje autom√°tico para realizar predicciones precisas, convirtiendo im√°genes de d√≠gitos escritos a mano en su representaci√≥n num√©rica correspondiente.

# Estructura del proyecto
El siguiente diagrama describe la estructura actual del proyecto **Predicci√≥n de D√≠gitos**

``` text
.
‚îú‚îÄ‚îÄ digits_model/
‚îÇ   ‚îú‚îÄ‚îÄ digits_model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ urls.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clf.pickle
‚îÇ   ‚îú‚îÄ‚îÄ predicciones/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ apps.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ views.py
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ digit_42.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ data_generator.ipynb
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ dockerfile
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```
* `digits_model/`: en este directorio se encuentra contenida la aplicaci√≥n **backend (REST API)** encargada de **servir el modelo**. Dicho servicio se encuentra desarrollado en el **framework Django**.
  * `digits_model/digits_model/`: en este directorio se encuentra las configuraciones que requiere Django para servir la aplicaci√≥n como los **settings**, **urls** y **el Web Server Gateway Interface (WSGI)**
  * `digits_model/model/`: en este directorio se encuentra el **modelo clf.pickle** encargado de inferir el d√≠gito representando en una imagen.
  * `digits_model/predicciones/`: este directorio representa la aplicaci√≥n (app) del proyecto **digits_model**, ac√° se encuentra definidas las vistas para cada una de las direcciones que posee la aplicaci√≥n referente a la predicci√≥n/inferencia del modelo.
  * `digits_model/templates`: en este directorio se encuentran los archivos `.html` que se renderizan en el cliente.  Una plantilla contiene las partes est√°ticas de la salida HTML.
  * `digits_model/manage.py`: representa el script de administraci√≥n de Django con √©l, podemos realizar acciones como: ejecutar el servidor, realizar migraciones, migraciones de modelo, etc.
* `test/` y `data_generator.ipynb`: este directorio contiene una serie de im√°genes para ser utilizadas como test de la aplicaci√≥n. Dichas im√°genes son generedas de manera aleatoria a la hora de ejecutar `data_generator.ipynb`.
* `.gitignore`: archivos ignorados por **git**.
* `app.py`: contiene un peque√±o script donde se ilustra c√≥mo importar y ejecutar el modelo **clf.pickle**.
* `docker-compose.yml`: contiene las instrucciones necesarias para ejecutar un contenedor a partir de la imagen Docker de la aplicaci√≥n.
* `dockerfile`: contiene las instrucciones para crear una imagen de la aplicaci√≥n.
* `README.md`: contiene la documentaci√≥n de este proyecto.
* `requirements.txt`: contiene todas las dependencias necesarias para la ejecutar la aplicaci√≥n.

# Ejecuci√≥n
A continuaci√≥n se indica como ejecutar la aplicaci√≥n de menera local sin usar Docker y de manera local usando Docker.
## Ejecuci√≥n Local (No Docker)

Para ejecutar la aplicaci√≥n de manera local **por primera vez** ejecutar los siguientes comandos:
> ‚ö†Ô∏è ***Es importante tener en cuenta que:***
> 
>   1. ***Versi√≥n de Python:** 3.11.7*
>   2. *A la hora de ejecutar los comandos que se muestran a continuaci√≥n aseg√∫rese de que se encuentre ubicado, en consola, en el directorio del proyecto.*

1. **Creaci√≥n del ambiente virtual**:
    ``` bash
    python -m venv .venv 
    ```
2. **Activaci√≥n del ambiente virtual**: 
    ```bash
    source .venv/Scripts/activate
    ```
3. **Instalaci√≥n de dependencias**:
    ```bash
    pip install -r requirements.txt
    ```

5. **Ejecutar la aplicaci√≥n**:
   
    ```bash
    python manage.py runserver
    ```
    > ‚ö†Ô∏è *A la hora de ejecutar la aplicaci√≥n es importante tener en cuenta que debemos estar ubicados, en consola, en la carpeta **`cd digits_model`***

Si no es la primera vez que ejecutas esta aplicaci√≥n y previamente ya has realizado los pasos anteriores, solo debes de ejecutar los pasos **2. Activaci√≥n del ambiente virtual** y **4. Ejecutar la aplicaci√≥n** de los mencionados anteriormente

## Ejecuci√≥n Local (Docker)
Para ejecutar la aplicaci√≥n en Docker de manera local aseg√∫rese en primera instancia de tener instalado Docker y luego ejecute los siguientes comandos:

> ‚ö†Ô∏è ***Es importante tener en cuenta que:** A la hora de ejecutar los comandos que se muestran a continuaci√≥n aseg√∫rese de que se encuentre ubicado, en consola, en el directorio del proyecto.*

1. **Creaci√≥n de la imagen virtual:**
   ```docker
   docker build --tag corona-model:v0 .
   ```
2. **Ejecuci√≥n del contenedor:**
    ```docker
    docker compose up
    ```
Si no es la primera vez que ejecutas la aplicaci√≥n de manera local usando Docker y ya posees una imagen virtual (imagen del paso **1 .Creaci√≥n de la imagen virtual**) puedes ejecutar directamente el paso  **2. Ejecuci√≥n del contenedor**.

---
# üìë REST API Documentation
## Instroducci√≥n
Esta API proporciona un √∫nico punto de acceso para hacer predicciones basadas en una imagen de entrada y un modelo de aprendizaje autom√°tico especificado. La API acepta una solicitud POST con un formulario que contiene un archivo de imagen y el nombre del modelo, y devuelve el resultado de la predicci√≥n.

### Base URL
* **[DEV - Docker]**: http://localhost:80/
* **[DEV - No Docker]**: http://localhost:8000/
* **[PROD]**: http://44.201.153.114:8000/

> ‚ö†Ô∏è ***Es importante tener en cuenta que:** para usar la Base URL de desarrollo debemos de tener en ejecuci√≥n la aplicaci√≥n en la m√°quina local, ya sea en un contenedor o no.*

## Endpoints

### POST `{{Base URL}}/predict/`
Este endpoint acepta un archivo de imagen y un nombre de modelo, y devuelve una predicci√≥n basada en el modelo proporcionado.

**Request**.
* **Method**: POST
* **Endpoint**: /predict/
* **Content-Type**: multipart/form-data

**Par√°metros**.

El cuerpo (**body**) de la solicitud debe contener los siguientes dos par√°metros como **form-data**.

| **Par√°metro** | **Tipo** | **Requerido** | **Descripci√≥n**                                           |
| ------------- | -------- | ------------- | --------------------------------------------------------- |
| **image**     | file     | S√≠            | Imagen que ser√° usada para la inferencia.                 |
| **model**     | string   | S√≠            | Nombre del modelo de Machine Learning usado para inferir. |

**Ejemplo request**
```bash
curl -X POST {{Base URL}}/predict/ \
  -F 'image=@/path/to/your/image.jpg' \
  -F 'model=clf.pickle'

> {
    "status_code": 200,
    "query_id": "70cd7b2a-dd66-4fce-b13a-cede33c80422",
    "prediction": 2,
    "execution_time": "2.08 seg"
}
```
donde:
| **Campo**          | **Tipo** | **Descripci√≥n**                                                             |
| ------------------ | -------- | --------------------------------------------------------------------------- |
| **success**        | int      | 200 para indicar que la petici√≥n fue exitosa.                               |
| **query_id**       | string   | uuid que identifica de manera √∫nica la petici√≥n.                            |
| **prediction**     | int      | Predicci√≥n del modelo basado en la imagen.                                  |
| **execution_time** | string   | Tiempo que le toma al modelo en realizar una predicci√≥n medida en segundos. |
| **error**          | string   | Mensaje de error si la consulta falla (opcional)                            |

# Arquitectura en Producci√≥n

A continuaci√≥n se muestra la arquitectura empleada en AWS que sirve al modelo actualmente. 

> *Recordar que la aplicaci√≥n se encuentra desplegada en http://44.201.153.114:8000/*

![arquitectura](./arquitectura.png)

---
# Estrategia para la detecci√≥n de Drift

Para abordar el problema del **drift** en datos en un sistema de machine learning en producci√≥n, se propone una estrategia que abarque: 
1. Detecci√≥n.
2. Reentrenamiento.
3. Automatizaci√≥n.

## Detecci√≥n
El **drift** de los datos puede presentarse como un cambio en las distribuciones estad√≠sticas de los datos de entrada. Por tal motivo es importante comparar la distribuci√≥n de los datos de entrada actuales con los datos de entrenamiento. Cambios significativos pueden se√±alar un **drift**.

**Servicios**:
* **Amazon CloudWatch**: Para monitorear m√©tricas del modelo en tiempo real como la precisi√≥n o error.
* **Amazon S3**: Almacenar datos hist√≥ricos para comparar distribuciones.
* **AWS Lambda**: Para ejecutar scripts que detecten drift peri√≥dicamente (Usar m√©tricas estad√≠sticas como el **Wasserstein distance** para comparar la distribuci√≥n actual de los datos con la distribuci√≥n que se utiliz√≥ para entrenar el modelo originalmente).
  
## Reentrenamiento
Una vez que se detecta drift, es esencial tener una estrategia que permita decidir cu√°ndo y c√≥mo reentrenar el modelo para corregir la p√©rdida de precisi√≥n.

> ‚ö†Ô∏è ***Es importante tener en cuenta que:***
> 
> 1. *Es importante no reentrenar con mucha frecuencia, ya que esto puede ser costoso y causar sobreajuste. Se deben definir reglas claras basadas en la severidad del drift detectado.*
> 2. *Para que el reentrenamiento sea efectivo, se debe evaluar si hay suficientes datos nuevos que representen adecuadamente la nueva distribuci√≥n o cambios en el comportamiento del negocio.*

**Servicios:**

* **Amazon S3**: Almacenar los nuevos datos de entrada y los conjuntos de datos para el reentrenamiento.
* **Amazon SageMaker**: Para entrenar, evaluar, y versionar nuevos modelos de manera escalable.
* **AWS Step Functions**: Orquestar el flujo de trabajo automatizado para la detecci√≥n del drift, reentrenamiento, y despliegue.
* **Amazon CloudWatch Events**: Programar y lanzar workflows de reentrenamiento.
* **AWS CodePipeline**: Para automatizar el despliegue del nuevo modelo.

## Automatizaci√≥n
El pipeline automatizado debe ser robusto para gestionar todas las etapas de recolecci√≥n de nuevos datos, reentrenamiento del modelo y despliegue sin interrupci√≥n del servicio.
### Arquitectura del Pipeline:
* **Recolecci√≥n de datos**: Implementaci√≥n de un sistema que peromita la recolecci√≥n de datos de manera continua.
    > ‚ö†Ô∏è ***Es importante tener en cuenta que**: se debe considerar una limpieza de datos en caso de que el proceso lo necesite.*
* **Reentrenamiento**: Configurar el sistema para que, cuando se detecte **drift** o se alcance una cantidad suficiente de nuevos datos, se dispare autom√°ticamente un proceso de reentrenamiento del modelo.
    > ‚ö†Ô∏è ***Es importante tener en cuenta que**: antes de desplegar el modelo, es fundamental validar el desempe√±o del modelo re-entrenado en un conjunto de validaci√≥n. Solo si supera a la versi√≥n actual en t√©rminos de precisi√≥n y estabilidad debe proceder al despliegue.*
* **Despliegue:**
  Es importante tener una estrategia que permita desplegar el nuevo modelo sin la necesidad de interrumpir el servicio. Para esto contamos con dos estrategias:
  * **Blue/Green Deployment**: Se puede implementar un enfoque de despliegue Blue/Green donde el nuevo modelo se despliega en paralelo al modelo existente. Solo despu√©s de comprobar su rendimiento en producci√≥n en tiempo real, se puede hacer la transici√≥n completa.
  * **Canary Deployment**: Otra opci√≥n es un despliegue canario donde el nuevo modelo se pruebe con una peque√±a porci√≥n del tr√°fico antes de aumentar gradualmente el porcentaje de solicitudes que maneja.

**Servicios**:
* **Amazon ECR**: Almacenar la nueva imagen de contenedor con el modelo reentrenado.
* **Amazon ECS**: Ejecutar el contenedor con el nuevo modelo.
* **AWS CodePipeline**: Para automatizar el proceso de despliegue.
* **Amazon CloudWatch**: Monitorear el rendimiento del nuevo modelo una vez desplegado.

## Desaf√≠os T√©cnicos y Operativos
* **Costos**: Ejecutar pipelines autom√°ticos, especialmente para entrenamiento en SageMaker, puede generar costos altos. 
* **Latencia del despliegue**: Aunque Blue/Green o Canary Deployments minimizan los riesgos, pueden aumentar la latencia temporalmente mientras se prueba el nuevo modelo.
* **Gesti√≥n de m√∫ltiples versiones**: Deber√°s asegurarte de que la infraestructura sea capaz de gestionar m√∫ltiples versiones de un modelo y revertir r√°pidamente si es necesario.
* **Compatibilidad entre versiones de modelo**: El nuevo modelo debe ser compatible con el sistema de producci√≥n existente, lo que implica garantizar que la estructura de entrada y salida no cambie dr√°sticamente.

A continuaci√≥n se presenta una arquitectura en AWS que describe los servicios anteriores mencionados de una manera simplificada para generar un almacenamiento, entrenamiento y despliegue automatizado.

![arquitectura-drift](./arquitectura-drift.png)